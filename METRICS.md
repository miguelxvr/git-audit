# Metrics Reference

Complete reference for all 38 metrics generated by git-audit.

## Metrics Table

All metrics organized by domain for easy reference:

| Metric | Type | Formula/Description | Range/Scale | Interpretation |
|--------|------|---------------------|-------------|----------------|
| **Author Information** |
| `author_name` | String | Author's full name from Git | N/A | Display name |
| `author_email` | String | Author's email address | N/A | Unique identifier |
| **Commits Domain** |
| `commits_non_merge` | Count [Base] | Regular commits (excluding merges) | 0+ | Higher = more contributions |
| `commits_merge` | Count [Base] | Merge commits | 0+ | Integration/coordination work |
| `commits_total` | Sum [Aggregated] | `commits_non_merge + commits_merge` | 0+ | Overall commit activity |
| `commits_freq` | Rate [Calculated] | `commits_non_merge / days_active` | 0.0+ | Commits per day |
| `commits_team_pct` | Percentage [Relative] | % of team's total commits | 0-100 | Team contribution share |
| `commits_first_date` | Date [Timeline] | First commit date | YYYY-MM-DD | When developer joined |
| `commits_last_date` | Date [Timeline] | Last commit date | YYYY-MM-DD | Last contribution date |
| **Lines Domain** |
| `lines_added` | Count [Base] | Lines added across all commits | 0+ | Volume of additions |
| `lines_deleted` | Count [Base] | Lines deleted across all commits | 0+ | Volume of deletions/refactoring |
| `lines_total` | Sum [Aggregated] | `lines_added + lines_deleted` | 0+ | Total code churn |
| `lines_per_commit_avg` | Average [Calculated] | `lines_total / commits_non_merge` | 0.0+ | Optimal: 50-500 |
| `lines_churn_ratio` | Ratio [Calculated] | `lines_deleted / lines_added` | 0.0+ | Lower is better (<0.2 = new code) |
| `lines_team_pct` | Percentage [Relative] | % of team's total lines | 0-100 | Code volume share |
| **Files Domain** |
| `files_added` | Count [Base] | New files created | 0+ | New features/modules |
| `files_deleted` | Count [Base] | Files removed | 0+ | Cleanup/refactoring |
| `files_modified` | Count [Base] | Existing files modified | 0+ | Updates to existing code |
| `files_binary` | Count [Base] | Binary files changed | 0+ | Assets/images (non-code) |
| `files_touched` | Count [Base] | Distinct files modified | 0+ | Codebase coverage |
| `files_total` | Sum [Aggregated] | `files_added + files_deleted + files_modified + files_binary` | 0+ | Breadth of file operations |
| `files_per_commit_avg` | Average [Calculated] | `files_total / commits_non_merge` | 0.0+ | Optimal: 1-3 (focused) |
| `files_team_pct` | Percentage [Relative] | % of team's files | 0-100 | Codebase coverage share |
| **Days Domain** |
| `days_active` | Count [Base] | Distinct days with commits | 0+ | Consistency measure |
| `days_span` | Duration [Calculated] | Days from first to last commit | 0+ | Project tenure |

## Evaluation Indicators Table

All evaluation indicators normalized to 0.0-1.0 scale (higher = better performance):

| Indicator | Dimension | Method | Description | Factors/Formula |
|-----------|-----------|--------|-------------|-----------------|
| **Productivity** | | | **Measures volume and consistency** |
| `prod_rel` | Productivity | Team min-max | Compared to team best/worst | - |
| `prod_abs` | Productivity | Thresholds | Against benchmarks (50 commits excellent, 5 poor) | - |
| `prod_stat` | Productivity | Percentile | Ranking within team | - |
| `prod_score` | Productivity | **Average** | Overall productivity score | **Avg of above 3 methods** |
| | | | *Factors:* | 40% commits, 30% lines, 20% files, 10% days |
| **Quality** | | | **Measures code quality practices** |
| `quality_rel` | Quality | Team min-max | Compared to team best/worst | - |
| `quality_abs` | Quality | Thresholds | Against benchmarks (churn <0.2, size 50-500) | - |
| `quality_stat` | Quality | Percentile | Ranking within team | - |
| `quality_score` | Quality | **Average** | Overall quality score | **Avg of above 3 methods** |
| | | | *Factors:* | 35% churn, 25% size, 25% files/commit, 15% merge ratio |
| **Collaboration** | | | **Measures team integration** |
| `collab_rel` | Collaboration | Team min-max | Compared to team best/worst | - |
| `collab_abs` | Collaboration | Thresholds | Against benchmarks (≥5 merges, ≥50% shared) | - |
| `collab_stat` | Collaboration | Percentile | Ranking within team | - |
| `collab_score` | Collaboration | **Average** | Overall collaboration score | **Avg of above 3 methods** |
| | | | *Factors:* | 40% merge activity, 35% shared files, 25% span |
| **Overall** | | | **Aggregate performance** |
| `overall_score` | All | **Weighted** | Final developer score | **33.3% productivity + 33.3% quality + 33.4% collaboration** |

**Score Interpretation:**
- **0.7-1.0** = Excellent performance
- **0.4-0.7** = Good/solid performance
- **0.0-0.4** = Area for improvement or specialized role


## Normalization Methods

Three methods are used to normalize evaluation indicators (each produces a 0.0-1.0 score):

| Method | Formula | Best For | Pros | Cons |
|--------|---------|----------|------|------|
| **Relative** | `(value - team_min) / (team_max - team_min)` | Team comparison | Easy interpretation, shows who's leading | Dependent on team composition |
| **Absolute** | Linear scale between "excellent" and "poor" thresholds | External benchmarks | Independent of team, stable over time | Thresholds may not fit all contexts |
| **Statistical** | `(count_below + 0.5 * count_equal) / total` | Robust ranking | Handles outliers well, fair ranking | Less intuitive than other methods |
| **Average** | Mean of above 3 methods | Balanced view | Combines all perspectives | May hide extremes |

**Note:** Each dimension score (`productivity_score`, `quality_score`, `collaboration_score`) is the average of its 3 normalization methods.
